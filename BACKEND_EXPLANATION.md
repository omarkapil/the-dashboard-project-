# ðŸ§  Backend Explanation â€” SME Cyber Exposure Dashboard
### *A Beginner-Friendly, Line-by-Line Guide*

> ðŸ“… Last Updated: February 2026  
> ðŸ‘¤ Author: Project Team  
> ðŸŽ¯ Purpose: Help any beginner understand how the backend works, file by file, line by line.

---

## ðŸ“ The Backend Folder Structure

Before we dive in, here's a map of what exists in the backend so you can visualize the whole system:

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              â† The ENTRY POINT â€” where everything starts
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py        â† Settings & environment variables
â”‚   â”‚   â”œâ”€â”€ database.py      â† Database connection
â”‚   â”‚   â”œâ”€â”€ risk_engine.py   â† Calculates risk scores for assets
â”‚   â”‚   â””â”€â”€ celery_app.py    â† Background job scheduler
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ scan.py          â† Database table definitions
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ api.py           â† URL routing (which URL goes where)
â”‚   â””â”€â”€ services/            â† The business logic (scanning, AI, etc.)
â”‚       â”œâ”€â”€ agent_orchestrator.py
â”‚       â”œâ”€â”€ ai_advisor.py
â”‚       â”œâ”€â”€ nmap_wrapper.py
â”‚       â”œâ”€â”€ nuclei_wrapper.py
â”‚       â”œâ”€â”€ openvas.py
â”‚       â”œâ”€â”€ pdf_generator.py
â”‚       â”œâ”€â”€ risk_engine.py
â”‚       â””â”€â”€ scan_tasks.py
```

---

## ðŸŸ¢ Part 1: `main.py` â€” The Entry Point (The Front Door of Your App)

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.core.config import settings
from app.api.api import api_router
from app.core.database import engine, Base

Base.metadata.create_all(bind=engine)

app = FastAPI(
    title=settings.PROJECT_NAME,
    openapi_url=f"{settings.API_V1_STR}/openapi.json"
)

if settings.BACKEND_CORS_ORIGINS:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=[str(origin) for origin in settings.BACKEND_CORS_ORIGINS],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

app.include_router(api_router, prefix=settings.API_V1_STR)

@app.get("/")
def read_root():
    return {"message": "Welcome to SME Cyber Exposure Dashboard API"}
```

### ðŸ” Line-by-Line Explanation

| Line | What it does |
|------|--------------|
| `from fastapi import FastAPI` | Imports the **FastAPI** library. FastAPI is the framework we use to build our API server â€” think of it like a restaurant kitchen manager who receives orders (HTTP requests) and sends back food (responses). |
| `from fastapi.middleware.cors import CORSMiddleware` | Imports **CORS middleware**. CORS is a browser security feature. Without this, your frontend (React) would be **blocked** from talking to your backend because they run on different ports. |
| `from app.core.config import settings` | Imports our app's **settings file** (explained in Part 2). Think of `settings` as a notebook containing all app configurations. |
| `from app.api.api import api_router` | Imports our **URL router** â€” basically the map that says "when someone visits `/scans`, call this function". |
| `from app.core.database import engine, Base` | Imports the **database engine** (the connection to SQLite/PostgreSQL) and `Base` (the parent class all database models inherit from). |
| `Base.metadata.create_all(bind=engine)` | **Auto-creates all database tables** on startup if they don't exist. It looks at all your model classes and builds the database schema for you. |
| `app = FastAPI(title=..., openapi_url=...)` | **Creates the app instance**. The `title` shows in the auto-generated API docs. `openapi_url` is where the docs JSON lives so tools like Swagger can read it. |
| `app.add_middleware(CORSMiddleware, ...)` | **Attaches CORS rules** so the frontend at `localhost:5173` (React/Vite) is allowed to call the backend at `localhost:8000`. `allow_methods=["*"]` means all HTTP methods (GET, POST, DELETE, etc.) are accepted. |
| `app.include_router(api_router, ...)` | **Registers all routes** (URLs) from `api_router` under the prefix `/api/v1`. So `/scans` becomes `/api/v1/scans`. |
| `@app.get("/")` | A **decorator** that says: "When someone visits the root URL `/`, run this function." |
| `return {"message": "Welcome..."}` | Returns a **JSON response** â€” proof the server is alive. |

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 1
> Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ **Ø¨Ø§Ø¨ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ** Ù„Ù„ØªØ·Ø¨ÙŠÙ‚. Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±ØŒ Ù‡Ø°Ø§ Ø£ÙˆÙ„ Ù…Ù„Ù ÙŠÙØ­Ù…ÙŽÙ‘Ù„. ÙŠÙ‚ÙˆÙ… Ø¨Ù€:
> - Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ FastAPI
> - Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (React) Ø¨Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¹Ø¨Ø± Ø¥Ø¹Ø¯Ø§Ø¯ CORS
> - Ø±Ø¨Ø· Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª (URLs) Ø¨Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
> - Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯Ø§ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„

---

## âš™ï¸ Part 2: `core/config.py` â€” The Settings Notebook

```python
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import List

class Settings(BaseSettings):
    PROJECT_NAME: str = "SME Cyber Exposure Dashboard"
    API_V1_STR: str = "/api/v1"
    DATABASE_URL: str = "sqlite:///./test.db"
    REDIS_URL: str = "redis://localhost:6379/0"
    NMAP_PATH: str = "nmap"
    OPENVAS_HOST: str = "localhost"
    OPENVAS_PORT: int = 9390
    OPENVAS_USER: str = "admin"
    OPENVAS_PASSWORD: str = "admin"
    GEMINI_API_KEY: str = ""
    BACKEND_CORS_ORIGINS: List[str] = ["http://localhost:5173", "http://localhost:3000"]

    model_config = SettingsConfigDict(case_sensitive=True, env_file=".env")

settings = Settings()
```

### ðŸ” Explanation

| Setting | Purpose |
|---------|---------|
| `BaseSettings` | A special class from `pydantic` that reads values from your `.env` file automatically. So instead of hardcoding passwords in code (dangerous!), they get loaded from the `.env` file on your computer. |
| `PROJECT_NAME` | Just the display name of the project. |
| `API_V1_STR = "/api/v1"` | The **URL prefix** for all endpoints. Every API route starts with `/api/v1/`. |
| `DATABASE_URL` | Tells the backend **where the database is**. By default it uses `SQLite` (a file-based database, `test.db`), but in production you'd switch to PostgreSQL. |
| `REDIS_URL` | The address of the **Redis server**, which is used by Celery for background job queues. |
| `NMAP_PATH` | The command to run **Nmap** (network scanner tool). `"nmap"` means it's installed globally on the system. |
| `OPENVAS_*` | Connection details for **OpenVAS**, the vulnerability scanner. |
| `GEMINI_API_KEY` | Your **Google Gemini AI** key, used to power the AI advisor and vulnerability analysis. |
| `BACKEND_CORS_ORIGINS` | A list of allowed frontend URLs. React dev server runs on port `5173`, so we whitelist it here. |
| `model_config = SettingsConfigDict(env_file=".env")` | Tells Pydantic to read secrets from the `.env` file in your project root. |
| `settings = Settings()` | Creates **one single instance** of the settings. All other files import this one object. |

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 2
> Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ **Ø¯ÙØªØ± Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª** Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„. ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
> - Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆØ¹Ù†ÙˆØ§Ù† API
> - Ø¹Ù†ÙˆØ§Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (SQLite Ø£Ùˆ PostgreSQL)
> - Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Redis ÙˆCelery Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©
> - Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© (Nmap, OpenVAS) ÙˆÙ…ÙØªØ§Ø­ Gemini AI
> - ÙŠÙ‚Ø±Ø£ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ø³Ø§Ø³Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù…Ù† Ù…Ù„Ù `.env` Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ÙƒØªØ§Ø¨ØªÙ‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯

---

## ðŸ—„ï¸ Part 3: `core/database.py` â€” The Database Connection

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, DeclarativeBase
from app.core.config import settings

engine = create_engine(
    settings.DATABASE_URL,
    connect_args={"check_same_thread": False} if "sqlite" in settings.DATABASE_URL else {}
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

class Base(DeclarativeBase):
    pass

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

### ðŸ” Explanation

| Code | Purpose |
|------|---------|
| `create_engine(...)` | Creates the **database engine** â€” the telephone line between Python and the database. `check_same_thread: False` is an SQLite-specific fix so multiple requests can share the database. |
| `SessionLocal = sessionmaker(...)` | A **factory** that creates sessions. A `Session` is like a shopping cart â€” you add/remove/query items, then `commit()` to save changes. If something goes wrong, you can `rollback()`. |
| `autocommit=False` | Changes are **not saved automatically**. You must call `db.commit()` explicitly. |
| `autoflush=False` | SQLAlchemy won't push pending changes before every query. Gives you more control. |
| `class Base(DeclarativeBase)` | The **parent class** for all database models. Every table (`Scan`, `Target`, `Vulnerability`) inherits from this. |
| `def get_db()` | A **dependency injection function**. Creates a fresh database session, hands it to the API function (`yield db`), and **always closes it** in the `finally` block â€” even if something crashes. Prevents connection leaks. |

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 3
> Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ **Ù‚Ù†Ø§Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙŠÙ† Ø§Ù„ÙƒÙˆØ¯ ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**. ÙŠÙ‚ÙˆÙ… Ø¨Ù€:
> - Ø¥Ù†Ø´Ø§Ø¡ "Ù…Ø­Ø±Ùƒ" Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (SQLite Ø£Ùˆ PostgreSQL)
> - Ø¥Ù†Ø´Ø§Ø¡ "Ø¬Ù„Ø³Ø©" Ù„ÙƒÙ„ Ø·Ù„Ø¨ API (Ù…Ø«Ù„ ÙØªØ­ Ø§ØªØµØ§Ù„ Ù…Ø¤Ù‚Øª)
> - `get_db()` ØªØ¶Ù…Ù† Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø¹Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©ØŒ Ø­ØªÙ‰ ÙÙŠ Ø­Ø§Ù„Ø© Ø­Ø¯ÙˆØ« Ø®Ø·Ø£

---

## ðŸ—ºï¸ Part 4: `api/api.py` â€” The URL Router (The Traffic Map)

```python
from fastapi import APIRouter
from app.api.v1.endpoints import scans, reports, network, targets, vulnerabilities, openvas, dashboard

api_router = APIRouter()

api_router.include_router(targets.router, prefix="/targets", tags=["targets"])
api_router.include_router(scans.router, prefix="/scans", tags=["scans"])
api_router.include_router(vulnerabilities.router, prefix="/vulnerabilities", tags=["vulnerabilities"])
api_router.include_router(reports.router, prefix="/reports", tags=["reports"])
api_router.include_router(network.router, prefix="/network", tags=["network"])
api_router.include_router(openvas.router, prefix="/openvas", tags=["openvas"])
api_router.include_router(dashboard.router, prefix="/dashboard", tags=["dashboard"])

@api_router.get("/")
def root():
    return {"message": "PentesterFlow API is running", "version": "2.0"}
```

### ðŸ” Explanation

- **`APIRouter()`** â€” Creates a **router object** â€” a container that groups related URLs together. Think of it like a **switchboard operator** who routes incoming calls to the right department.

- **`include_router(targets.router, prefix="/targets")`** â€” Any URL starting with `/targets` is handled by the `targets` module. Full URL examples:
  - `GET /api/v1/targets` â†’ lists all targets
  - `POST /api/v1/targets` â†’ creates a new target
  - `DELETE /api/v1/targets/123` â†’ deletes target with ID 123

- **`tags=[...]`** â€” Labels that appear in the auto-generated Swagger API documentation.

- Full URL structure: `http://localhost:8000` + `/api/v1` + `/scans` = `http://localhost:8000/api/v1/scans`

### ðŸ—‚ï¸ Available Endpoints Summary

| Prefix | Module | Purpose |
|--------|--------|---------|
| `/targets` | `targets.py` | Manage scan targets (websites/apps) |
| `/scans` | `scans.py` | Start, stop, and view security scans |
| `/vulnerabilities` | `vulnerabilities.py` | View and manage discovered vulnerabilities |
| `/reports` | `reports.py` | Generate and download PDF reports |
| `/network` | `network.py` | Network asset inventory |
| `/openvas` | `openvas.py` | OpenVAS vulnerability scanner integration |
| `/dashboard` | `dashboard.py` | Summary statistics for the dashboard UI |

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 4
> Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ **Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª (URLs)** Ù„Ù„ØªØ·Ø¨ÙŠÙ‚. ÙŠÙˆØ¬Ù‘Ù‡ ÙƒÙ„ Ø·Ù„Ø¨ HTTP Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨:
> - `/targets` â†’ ÙƒÙ„ Ù…Ø§ ÙŠØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ø£Ù‡Ø¯Ø§Ù
> - `/scans` â†’ Ø§Ù„ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©
> - `/vulnerabilities` â†’ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©
> - `/dashboard` â†’ Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…

---

## ðŸ—ï¸ Part 5: `models/scan.py` â€” The Database Blueprint

This is one of the **most important files** in the backend. It defines what every table in your database looks like â€” like designing the columns in an Excel spreadsheet before you fill in the data.

### ðŸ“Œ 5.1 â€” Enums (Predefined Value Lists)

```python
class ScanStatus(str, enum.Enum):
    QUEUED = "queued"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"

class SeverityLevel(str, enum.Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

class VulnStatus(str, enum.Enum):
    OPEN = "open"
    FIXED = "fixed"
    FALSE_POSITIVE = "false_positive"
    ACCEPTED = "accepted"
```

**Enums** are like a **multiple-choice list**. Instead of allowing any random text into a database column, you restrict it to specific allowed values. This prevents typos and invalid data.

- A scan can only ever be: `queued`, `running`, `completed`, or `failed`
- A vulnerability severity can only be: `critical`, `high`, `medium`, `low`, or `info`

---

### ðŸ“Œ 5.2 â€” The `Target` Table

```python
class Target(Base):
    __tablename__ = "targets"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String(255), nullable=False)
    base_url = Column(Text, nullable=False)
    source = Column(String(50), default="manual")
    tech_stack = Column(JSON, nullable=True)
    auth_method = Column(String(50), nullable=True)
    auth_credentials = Column(JSON, nullable=True)
    asset_value = Column(Enum("CRITICAL","HIGH","MEDIUM","LOW"), default="MEDIUM")
    data_sensitivity = Column(Enum("PII","FINANCIAL","NONE"), default="NONE")

    scans = relationship("Scan", back_populates="target", cascade="all, delete-orphan")
    endpoints = relationship("Endpoint", back_populates="target", cascade="all, delete-orphan")
```

A **Target** is a website or application you want to scan. Each column is a field for that target:

| Column | Purpose |
|--------|---------|
| `id` | Unique UUID (like a barcode) auto-generated for each target |
| `name` | Human-readable name, e.g. `"Company Main Website"` |
| `base_url` | The actual URL, e.g. `https://company.com` |
| `source` | Did you add it manually? Or did the discovery agent find it? (`manual`, `discovery`, `aws`) |
| `tech_stack` | JSON object storing detected technologies e.g. `{"cms": "WordPress", "server": "Nginx"}` |
| `auth_method` | How to authenticate: `jwt`, `cookie`, `basic`, or `none` |
| `asset_value` | Business importance: `CRITICAL` / `HIGH` / `MEDIUM` / `LOW` |
| `data_sensitivity` | Does it handle personal data (`PII`) or financial data? |
| `scans` (relationship) | Links to all Scans done on this target |
| `cascade="all, delete-orphan"` | If you delete a Target, all its related Scans are automatically deleted |

---

### ðŸ“Œ 5.3 â€” The `Scan` Table

```python
class Scan(Base):
    __tablename__ = "scans"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    target_id = Column(String(36), ForeignKey("targets.id"), nullable=True)
    target_url = Column(String, index=True, nullable=True)
    status = Column(Enum(ScanStatus), default=ScanStatus.QUEUED)
    scan_type = Column(String(50), default="full")
    start_time = Column(DateTime, nullable=True)
    end_time = Column(DateTime, nullable=True)
    agent_thoughts = Column(JSON, nullable=True)
    risk_score = Column(Float, default=0.0)
```

A **Scan** represents one security scanning session. When you click "Start Scan" on the dashboard, a new Scan record is created here.

| Column | Purpose |
|--------|---------|
| `target_id` | **Foreign Key** â€” links this scan to a Target (like a relationship/join table) |
| `status` | Current state: `queued â†’ running â†’ completed` |
| `scan_type` | `"full"`, `"quick"`, or `"custom"` |
| `agent_thoughts` | JSON logs from the AI agent â€” its "thinking process" stored for transparency |
| `risk_score` | Calculated risk score (0â€“100+) after the scan finishes |
| `@property` methods | `vulnerabilities_count`, `assets_count`, `target_display` compute values on the fly without storing them in the DB |

---

### ðŸ“Œ 5.4 â€” The `Vulnerability` Table

```python
class Vulnerability(Base):
    __tablename__ = "vulnerabilities"

    id = Column(String(36), primary_key=True, ...)
    scan_id = Column(String(36), ForeignKey("scans.id"))
    type = Column(String(100))           # SQLi, XSS, IDOR, BOLA
    severity = Column(Enum(SeverityLevel), ...)
    url = Column(Text, nullable=False)
    evidence = Column(JSON, nullable=True)
    confidence_score = Column(Float, nullable=True)
    ai_validation_result = Column(JSON, nullable=True)
    remediation = Column(Text, nullable=True)
    simplified_description = Column(Text, nullable=True)
```

Each vulnerability found by a scan is stored here.

| Column | Purpose |
|--------|---------|
| `type` | Type of vulnerability: `SQLi` (SQL Injection), `XSS`, `BOLA`, `IDOR` |
| `severity` | How dangerous it is: Critical / High / Medium / Low / Info |
| `evidence` | Raw HTTP request/response proving the vulnerability is real |
| `confidence_score` | How confident the AI is: `0.9` = 90% sure it's a real vulnerability |
| `ai_validation_result` | The Gemini AI analysis result stored as JSON |
| `remediation_steps` | Step-by-step fix instructions |
| `simplified_description` | AI-generated plain English explanation for non-technical people |

---

### ðŸ“Œ 5.5 â€” Other Important Tables

| Table | Purpose |
|-------|---------|
| `AgentLog` | Records every action the AI agent takes â€” great for auditing and debugging |
| `Endpoint` | Discovered API endpoints on a target (e.g. `GET /api/users`, `POST /api/login`) |
| `ScanAsset` | Network devices found during a scan (IP, hostname, OS, MAC address) |
| `AssetService` | Open ports/services on each network device (port 80 = HTTP, port 22 = SSH) |
| `NetworkAsset` | Persistent device inventory across all scans |
| `ActionItem` | Auto-generated to-do tasks when a high-risk asset is found |

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 5
> Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ **Ù…Ø®Ø·Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**. ÙƒÙ„ ÙƒÙ„Ø§Ø³ (class) Ù‡Ùˆ Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
> - **Target**: Ø§Ù„Ø£Ù‡Ø¯Ø§Ù (Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø±Ø§Ø¯ ÙØ­ØµÙ‡Ø§)
> - **Scan**: Ø¬Ù„Ø³Ø§Øª Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£Ù…Ù†ÙŠ
> - **Vulnerability**: Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©
> - **AgentLog**: Ø³Ø¬Ù„Ø§Øª ØªÙÙƒÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
> - **ScanAsset**: Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø´Ø¨ÙƒÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©
> - Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ (relationships) ØªØ±Ø¨Ø·Ù‡Ø§ Ø¨Ø¨Ø¹Ø¶Ù‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Foreign Keys

---

## ðŸ§® Part 6: `core/risk_engine.py` â€” The Risk Calculator

```python
class RiskEngine:
    def calculate_asset_risk(self, asset: NetworkAsset):
        asset_value_map = {"CRITICAL": 10, "HIGH": 8, "MEDIUM": 5, "LOW": 2}
        asset_val_score = asset_value_map.get(str(asset.criticality).upper(), 5)

        vulns = self.db.query(Vulnerability).filter(
            Vulnerability.host == asset.ip_address,
            Vulnerability.status == "OPEN"
        ).all()

        for v in vulns:
            score = severity_scores.get(v.severity, 0)
            # tracks: max_severity, critical_count, high_count

        base_score = asset_val_score * max_severity
        additive = (critical_count * 10) + (high_count * 5) + (medium_count * 1)
        final_score = base_score + additive
        return float(final_score), critical_count, high_count
```

### ðŸ” Explanation

The **Risk Engine** is like an **accountant for danger**. It calculates how risky each network device is using this formula:

```
Risk Score = (Asset Importance Ã— Worst Vulnerability Severity)
           + (Critical Vulnerabilities Ã— 10)
           + (High Vulnerabilities Ã— 5)
           + (Medium Vulnerabilities Ã— 1)
```

**Examples:**
- A **Critical** server with a **Critical** vulnerability: `10 Ã— 10 = 100` ðŸ”´
- A **Low-value** device with only **Low** vulnerabilities: `2 Ã— 2 = 4` ðŸŸ¢

### Key Methods

| Method | Purpose |
|--------|---------|
| `calculate_asset_risk(asset)` | Calculates the risk score for one single asset |
| `run_analysis()` | Loops through ALL assets, updates their scores, creates ActionItems for dangerous ones |
| `_create_action_item(asset, score, ...)` | Generates a prioritized task card if risk score is high enough |

### Priority Thresholds

| Score | Priority |
|-------|----------|
| > 80 | ðŸ”´ CRITICAL |
| > 60 | ðŸŸ  HIGH |
| > 50 | ðŸŸ¡ MEDIUM |

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 6
> **Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø®Ø§Ø·Ø±** ÙŠØ­Ø³Ø¨ Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© ÙƒÙ„ Ø¬Ù‡Ø§Ø² ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø§Ø¯Ù„Ø© ØªØ£Ø®Ø° Ø¨Ø¹ÙŠÙ† Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø±:
> - **Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¬Ù‡Ø§Ø²**: Ù‡Ù„ Ù‡Ùˆ Ø®Ø§Ø¯Ù… Ø±Ø¦ÙŠØ³ÙŠ Ø£Ù… Ø¬Ù‡Ø§Ø² Ø¹Ø§Ø¯ÙŠØŸ
> - **Ø®Ø·ÙˆØ±Ø© Ø§Ù„Ø«ØºØ±Ø§Øª**: ÙƒÙ… Ø«ØºØ±Ø© Ø­Ø±Ø¬Ø© ÙˆØ¹Ø§Ù„ÙŠØ© ØªÙˆØ¬Ø¯ Ø¹Ù„ÙŠÙ‡ØŸ
>
> Ø¥Ø°Ø§ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø¬Ù‡Ø§Ø² Ø¯Ø±Ø¬Ø© Ø®Ø·ÙˆØ±Ø© 50ØŒ ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© Ø¹Ù„Ø§Ø¬ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù„Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ø£Ù…Ù†ÙŠ ÙÙŠ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…

---

## â° Part 7: `core/celery_app.py` â€” The Background Job Scheduler

```python
from celery import Celery
from celery.schedules import crontab

celery_app = Celery(
    "worker",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL,
    include=['app.services.scan_tasks']
)

celery_app.conf.beat_schedule = {
    "hourly-network-scan": {
        "task": "app.services.scan_tasks.trigger_periodic_scan",
        "schedule": crontab(minute=0),  # Every hour at :00
        "args": ("localhost",),
    },
}
```

### ðŸ” Explanation

**Celery** is a **task queue system**. Imagine a restaurant â€” when a customer orders, the waiter doesn't stand in the kitchen waiting for the food to cook. They take the next order immediately, while the kitchen works in the background.

That's what Celery does for the backend:
- When a scan is triggered, instead of making the HTTP request wait for 5 minutes, Celery **puts the scan in a queue**
- The API immediately returns `{"status": "queued"}` to the user
- A **Celery worker** picks up the task and runs it in the background
- The frontend polls for updates

| Setting | Purpose |
|---------|---------|
| `broker=settings.REDIS_URL` | Where Celery **sends** tasks to â€” Redis is the message conveyor belt |
| `backend=settings.REDIS_URL` | Where Celery **stores task results** â€” also Redis |
| `include=[...]` | Which Python modules contain tasks Celery should know about |
| `beat_schedule` | An **automatic timer** â€” like a cron job. Runs `trigger_periodic_scan` every hour automatically |
| `crontab(minute=0)` | "Run at minute 0 of every hour" = every hour on the hour |

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 7
> **Celery** Ù‡Ùˆ Ù†Ø¸Ø§Ù… **Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©**. Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¬Ø¹Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠÙ†ØªØ¸Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ÙØ­Øµ (Ø§Ù„Ø°ÙŠ Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¯Ù‚Ø§Ø¦Ù‚):
> - ÙŠØªÙ… ÙˆØ¶Ø¹ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù†ØªØ¸Ø§Ø± ÙˆØªÙÙ†ÙÙŽÙ‘Ø° ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
> - **Redis** Ù‡Ùˆ "ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø¨Ø±ÙŠØ¯" Ø§Ù„Ø°ÙŠ ÙŠÙ†Ù‚Ù„ Ø§Ù„Ù…Ù‡Ø§Ù… Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
> - **beat_schedule** ÙŠØ´ØºÙ‘Ù„ ÙØ­ØµÙ‹Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ ÙƒÙ„ Ø³Ø§Ø¹Ø© Ø¯ÙˆÙ† ØªØ¯Ø®Ù„ Ø¨Ø´Ø±ÙŠ

---

## ðŸ”— Part 8: The Big Picture â€” How Everything Works Together

Here is the **complete flow** of what happens when a user clicks "Start Scan" on the dashboard:

```
Step 1: ðŸ–¥ï¸  Frontend (React) sends:
            POST http://localhost:8000/api/v1/scans
            Body: { "target_url": "https://company.com", "scan_type": "full" }

Step 2: ðŸšª  main.py receives the request and passes it to the router

Step 3: ðŸ—ºï¸  api.py looks at the URL (/scans) and routes it to scans.router

Step 4: ðŸ“‹  The scans endpoint function runs
            Reads configuration from config.py (settings)
            Uses get_db() from database.py to open a DB session

Step 5: ðŸ’¾  A new Scan record is saved to the DB with status = "queued"
            A response is immediately sent back: { "id": "abc-123", "status": "queued" }

Step 6: ðŸ“¦  A Celery task is sent to Redis
            The scan runs in the BACKGROUND (user doesn't wait)

Step 7: âš™ï¸  Worker runs the actual security tools:
            â†’ nmap_wrapper.py   (discovers open ports and services)
            â†’ nuclei_wrapper.py (tests for known CVEs and vulnerabilities)
            â†’ openvas.py        (deep vulnerability scanning)
            â†’ agent_orchestrator.py (AI agent coordinates everything)

Step 8: ðŸ’¾  All results are saved to the DB:
            â†’ Vulnerabilities â†’ vulnerabilities table
            â†’ Network devices â†’ scan_assets table
            â†’ AI thoughts     â†’ agent_logs table

Step 9: ðŸ§®  risk_engine.py calculates risk scores for all discovered assets
            If score > 50, an ActionItem is created automatically

Step 10: ðŸ¤– Gemini AI (ai_advisor.py) analyzes vulnerabilities:
             â†’ Validates findings
             â†’ Generates simplified descriptions
             â†’ Suggests remediation steps

Step 11: âœ…  The Scan status is updated to "completed"
             Frontend polls GET /api/v1/scans/abc-123 and displays results
```

> ### ðŸ“ Ù…Ù„Ø®Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ â€” Part 8 (Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©)
> Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ¶ØºØ· Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ "Ø§Ø¨Ø¯Ø£ Ø§Ù„ÙØ­Øµ":
> 1. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© ØªØ±Ø³Ù„ Ø·Ù„Ø¨Ù‹Ø§ Ù„Ù„Ø³ÙŠØ±ÙØ± Ø¹Ø¨Ø± API
> 2. Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠØ³ØªÙ„Ù… Ø§Ù„Ø·Ù„Ø¨ ÙˆÙŠÙˆØ¬Ù‡Ù‡ Ù„Ù„Ù…ÙƒØ§Ù† Ø§Ù„ØµØ­ÙŠØ­ Ø¹Ø¨Ø± Ø§Ù„Ø±Ø§ÙˆØªØ±
> 3. ÙŠÙØ­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ÙØ­Øµ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø­Ø§Ù„Ø© "ÙÙŠ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±"
> 4. ÙŠÙÙˆØ¶Ø¹ Ø§Ù„ÙØ­Øµ ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù†ØªØ¸Ø§Ø± Celery Ù„ØªÙ†ÙÙŠØ°Ù‡ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
> 5. ØªÙØ´ØºÙŽÙ‘Ù„ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ÙØ­Øµ Ø§Ù„ÙØ¹Ù„ÙŠØ© (NmapØŒ NucleiØŒ OpenVAS)
> 6. Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªÙØ­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
> 7. Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙŠØ­Ø³Ø¨ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø®Ø·ÙˆØ±Ø©
> 8. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Gemini) ÙŠØ­Ù„Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆÙŠÙ‚ØªØ±Ø­ Ø§Ù„Ø­Ù„ÙˆÙ„
> 9. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© ØªØ¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…

---

## ðŸ“š Quick Reference Glossary

| Term | Simple Explanation |
|------|--------------------|
| **FastAPI** | Python framework for building APIs fast. Like Django but lighter and faster |
| **API** | Application Programming Interface â€” a way for software to talk to each other |
| **Endpoint** | A specific URL in the API (e.g. `/api/v1/scans`) |
| **HTTP Method** | The type of request: GET (read), POST (create), PUT (update), DELETE (remove) |
| **SQLAlchemy** | Python library to interact with databases using Python code instead of SQL |
| **ORM** | Object Relational Mapper â€” lets you use Python classes instead of writing SQL queries |
| **Session** | A temporary connection to the database for one request |
| **Migration** | Controlled change to the database structure (like running an update) |
| **Celery** | Background job runner â€” handles long tasks so users don't wait |
| **Redis** | Fast in-memory database used as a message broker for Celery |
| **CORS** | Browser security feature â€” your backend must explicitly allow requests from the frontend |
| **JSON** | JavaScript Object Notation â€” a text format for sending structured data |
| **UUID** | Unique ID like `"550e8400-e29b-41d4-a716-446655440000"` â€” avoids ID collisions |
| **Foreign Key** | A column that links a row in one table to a row in another table |
| **Relationship** | SQLAlchemy links between tables so you can access related data easily |
| **Decorator** | `@app.get("/")` â€” a Python shortcut to attach extra behavior to a function |
| **Dependency Injection** | FastAPI automatically gives functions what they need (e.g. the DB session) |
| **Enum** | A fixed set of allowed string values (like a dropdown list) |
| **Pydantic** | Python library for data validation â€” ensures incoming data is the right type and shape |

---

*This document was auto-generated as part of the SME Cyber Exposure Dashboard project documentation.*
